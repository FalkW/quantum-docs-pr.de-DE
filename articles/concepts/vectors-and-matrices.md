---
title: Vektoren und Matrizen in Quantum Computing
description: Erfahren Sie mehr über die Grundlagen der Arbeit mit Vektoren und Matrizen.
author: QuantumWriter
uid: microsoft.quantum.concepts.vectors
ms.author: nawiebe@microsoft.com
ms.date: 12/11/2017
ms.topic: article
ms.openlocfilehash: 076ab6242b7ae31d4936ae8505034f1f13fa4727
ms.sourcegitcommit: 6ccea4a2006a47569c4e2c2cb37001e132f17476
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 02/28/2020
ms.locfileid: "77904909"
---
# <a name="vectors-and-matrices"></a><span data-ttu-id="23687-103">Vektoren und Matrizen</span><span class="sxs-lookup"><span data-stu-id="23687-103">Vectors and Matrices</span></span>

<span data-ttu-id="23687-104">Eine Vertrautheit mit Vektoren und Matrizen ist für das Verständnis von Quantum Computing von entscheidender Bedeutung.</span><span class="sxs-lookup"><span data-stu-id="23687-104">Some familiarity with vectors and matrices is essential to understand quantum computing.</span></span> <span data-ttu-id="23687-105">Im folgenden finden Sie eine kurze Einführung, und interessierte Leser werden empfohlen, einen Standard Verweis auf lineare Algebra zu lesen, z. b. für die Tabelle *, G. (1993). Einführung in lineare Algebra (Vol. 3). Wellesley, MA: Wellesley-Cambridge Press* oder eine Online Referenz, wie z. b. [lineare Algebra](http://joshua.smcvt.edu/linearalgebra/).</span><span class="sxs-lookup"><span data-stu-id="23687-105">We provide a brief introduction below and interested readers are recommended to read a standard reference on linear algebra such as *Strang, G. (1993). Introduction to linear algebra (Vol. 3). Wellesley, MA: Wellesley-Cambridge Press* or an online reference such as [Linear Algebra](http://joshua.smcvt.edu/linearalgebra/).</span></span>

<span data-ttu-id="23687-106">Ein Spalten Vektor (oder einfach [*Vektor*](https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics))) $v $ der Dimension (oder Größe) $n $ ist eine Auflistung von $n $ Complex-Zahlen (V_1, V_2, \ldots, v_n) $, die als Spalte angeordnet sind:</span><span class="sxs-lookup"><span data-stu-id="23687-106">A column vector (or simply [*vector*](https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics))) $v$ of dimension (or size) $n$ is a collection of $n$ complex numbers $(v_1,v_2,\ldots,v_n)$ arranged as a column:</span></span>

<span data-ttu-id="23687-107">$ $v = \begin{bmatrix} V_1\\\\ V_2\\\\ \vdots\\\\ v_n \end{bmatrix} $ $</span><span class="sxs-lookup"><span data-stu-id="23687-107">$$v =\begin{bmatrix} v_1\\\\ v_2\\\\ \vdots\\\\ v_n \end{bmatrix}$$</span></span>

<span data-ttu-id="23687-108">Die Norm eines Vector-$v $ ist als $ \sqrt{\sum\_i | v\_i | ^ 2} $ definiert.</span><span class="sxs-lookup"><span data-stu-id="23687-108">The norm of a vector $v$ is defined as $\sqrt{\sum\_i |v\_i|^2}$.</span></span> <span data-ttu-id="23687-109">Ein Vektor wird als Einheits Norm bezeichnet (oder alternativ als [*Einheits Vektor*](https://en.wikipedia.org/wiki/Unit_vector)bezeichnet), wenn seine Norm $1 $ ist.</span><span class="sxs-lookup"><span data-stu-id="23687-109">A vector is said to be of unit norm (or alternatively it is called a [*unit vector*](https://en.wikipedia.org/wiki/Unit_vector)) if its norm is $1$.</span></span> <span data-ttu-id="23687-110">Das [*Adjoint eines Vector*](https://en.wikipedia.org/wiki/Adjoint_matrix) -$v $ wird $v ^ \dagger $ bezeichnet und als folgender Zeilen Vektor definiert, wobei $\*$ die komplexe konjugierung bezeichnet.</span><span class="sxs-lookup"><span data-stu-id="23687-110">The [*adjoint of a vector*](https://en.wikipedia.org/wiki/Adjoint_matrix) $v$ is denoted $v^\dagger$ and is defined to be the following row vector where $\*$ denotes the complex conjugate,</span></span>

<span data-ttu-id="23687-111">$ $ \begin{bmatrix} V_1 \\\\ \vdots \\\\ v_n \end{bmatrix} ^ \dagger = \begin{bmatrix} V_1 ^ \* & \cdots & v_n ^ \* \end{bmatrix} $ $</span><span class="sxs-lookup"><span data-stu-id="23687-111">$$\begin{bmatrix}v_1 \\\\ \vdots \\\\ v_n \end{bmatrix}^\dagger = \begin{bmatrix}v_1^\* & \cdots & v_n^\* \end{bmatrix}$$</span></span>

<span data-ttu-id="23687-112">Die gängigste Methode, zwei Vektoren zu multiplizieren, ist das [*innere Produkt*](https://en.wikipedia.org/wiki/Inner_product_space), das auch als "Punktprodukt" bezeichnet wird.</span><span class="sxs-lookup"><span data-stu-id="23687-112">The most common way to multiply two vectors together is through the [*inner product*](https://en.wikipedia.org/wiki/Inner_product_space), also known as a dot product.</span></span>  <span data-ttu-id="23687-113">Das innere Produkt liefert die Projektion eines Vektors auf einen anderen und ist äußerst nützlich, um zu beschreiben, wie ein Vektor als Summe aus anderen einfacheren Vektoren ausgedrückt wird.</span><span class="sxs-lookup"><span data-stu-id="23687-113">The inner product gives the projection of one vector onto another and is invaluable in describing how to express one vector as a sum of other simpler vectors.</span></span>  <span data-ttu-id="23687-114">Das innere Produkt zwischen $u $ und $v $, bezeichnet $ \left\langle u, v\right\rangle $ ist definiert als</span><span class="sxs-lookup"><span data-stu-id="23687-114">The inner product between $u$ and $v$, denoted $\left\langle u, v\right\rangle$ is defined as</span></span>

<span data-ttu-id="23687-115">$ $ \langle u, v\rangle = u ^ \dagger v = u\_1 ^ {\*} V_1 + \cdots + u\_n ^ {\*} v\_n.</span><span class="sxs-lookup"><span data-stu-id="23687-115">$$ \langle u, v\rangle = u^\dagger v=u\_1^{\*} v_1 + \cdots + u\_n^{\*} v\_n.</span></span>
$$

<span data-ttu-id="23687-116">Diese Notation ermöglicht außerdem das Schreiben der Norm eines Vector-$v $ als $ \sqrt{\langle v, v\rangle} $.</span><span class="sxs-lookup"><span data-stu-id="23687-116">This notation also allows the norm of a vector $v$ to be written as $\sqrt{\langle v, v\rangle}$.</span></span>

<span data-ttu-id="23687-117">Wir können einen Vektor mit einer Zahl $c $ multiplizieren, um einen neuen Vektor zu bilden, dessen Einträge mit $c $ multipliziert werden.</span><span class="sxs-lookup"><span data-stu-id="23687-117">We can multiply a vector with a number $c$ to form a new vector whose entries are multiplied by $c$.</span></span> <span data-ttu-id="23687-118">Wir können auch zwei Vektoren $u $ und $v $ hinzufügen, um einen neuen Vektor zu bilden, dessen Einträge die Summe der Einträge von $u $ und $v $ sind.</span><span class="sxs-lookup"><span data-stu-id="23687-118">We can also add two vectors $u$ and $v$ to form a new vector whose entries are the sum of the entries of $u$ and $v$.</span></span> <span data-ttu-id="23687-119">Diese Vorgänge werden im folgenden dargestellt:</span><span class="sxs-lookup"><span data-stu-id="23687-119">These operations are depicted below:</span></span>

<span data-ttu-id="23687-120">$ $ \mathrm{if} ~ u = \begin{bmatrix} u_1\\\\ u_2\\\\ \vdots\\\\ u_n \end{bmatrix} ~ \mathrm{and} ~ v = \begin{bmatrix} V_1\\\\ V_2\\\\ \vdots\\\\ v_n \end{bmatrix}, ~ \mathrm{then} ~ au + BV = \begin{bmatrix} au_1 + bv_1\\\\ au_2 + bv_2\\\\ \vdots\\\\ au_n + bv_n \end{bmatrix}.</span><span class="sxs-lookup"><span data-stu-id="23687-120">$$\mathrm{If}~u =\begin{bmatrix} u_1\\\\ u_2\\\\ \vdots\\\\ u_n \end{bmatrix}~\mathrm{and}~ v =\begin{bmatrix} v_1\\\\ v_2\\\\ \vdots\\\\ v_n \end{bmatrix},~\mathrm{then}~ au+bv =\begin{bmatrix} au_1+bv_1\\\\ au_2+bv_2\\\\ \vdots\\\\ au_n+bv_n \end{bmatrix}.</span></span>
$$

<span data-ttu-id="23687-121">Eine [*Matrix*](https://en.wikipedia.org/wiki/Matrix_(mathematics)) der Größe $m \times n $ ist eine Auflistung von $MN $ komplexen Zahlen, die in $m $ Rows angeordnet sind, und $n $ Columns, wie unten dargestellt:</span><span class="sxs-lookup"><span data-stu-id="23687-121">A [*matrix*](https://en.wikipedia.org/wiki/Matrix_(mathematics)) of size $m \times n$ is a collection of $mn$ complex numbers arranged in $m$ rows and $n$ columns as shown below:</span></span>

<span data-ttu-id="23687-122">$ $M = \begin{bmatrix} M_{11} ~ ~ M_{12} ~ ~ \cdots ~ ~ M_ {1N}\\\\ M_{21} ~ ~ M_{22} ~ ~ \cdots ~ ~ M_ {2N}\\\\ \ddots\\\\ M_ {M1} ~ ~ M_ {m2} ~ ~ \cdots ~ ~ M_ {MN}\\\\ \end{bmatrix}. $ $</span><span class="sxs-lookup"><span data-stu-id="23687-122">$$M = \begin{bmatrix} M_{11} ~~ M_{12} ~~ \cdots ~~ M_{1n}\\\\ M_{21} ~~ M_{22} ~~ \cdots ~~ M_{2n}\\\\ \ddots\\\\ M_{m1} ~~ M_{m2} ~~ \cdots ~~ M_{mn}\\\\ \end{bmatrix}.$$</span></span>

<span data-ttu-id="23687-123">Beachten Sie, dass ein Vektor von Dimension $n $ einfach eine Matrix der Größe $n \times $1 ist.</span><span class="sxs-lookup"><span data-stu-id="23687-123">Note that a vector of dimension $n$ is simply a matrix of size $n \times 1$.</span></span> <span data-ttu-id="23687-124">Wie bei Vektoren können wir eine Matrix mit einer Zahl $c $ multiplizieren, um eine neue Matrix zu erhalten, in der jeder Eintrag mit $c $ multipliziert wird. Wir können zwei Matrizen derselben Größe hinzufügen, um eine neue Matrix zu generieren, deren Einträge die Summe der entsprechenden Einträge der beiden Matrizen sind.</span><span class="sxs-lookup"><span data-stu-id="23687-124">As with vectors, we can multiply a matrix with a number $c$ to obtain a new matrix where every entry is multiplied with $c$, and we can add two matrices of the same size to produce a new matrix whose entries are the sum of the respective entries of the two matrices.</span></span> 

## <a name="matrix-multiplication-and-tensor-products"></a><span data-ttu-id="23687-125">Matrix Multiplikation und Tensor-Produkte</span><span class="sxs-lookup"><span data-stu-id="23687-125">Matrix Multiplication and Tensor Products</span></span>

<span data-ttu-id="23687-126">Wir können auch zwei Matrizen $M $ of Dimension $m \times n $ und $N $ of Dimension $n \time p $ multiplizieren, um eine neue Matrix $P $ of Dimension $m \times p $ wie folgt zu erhalten:</span><span class="sxs-lookup"><span data-stu-id="23687-126">We can also multiply two matrices $M$ of dimension $m\times n$ and $N$ of dimension $n \times p$ to get a new matrix $P$ of dimension $m \times p$ as follows:</span></span>

<span data-ttu-id="23687-127">\begin{align} & \begin{bmatrix} M_{11} ~ ~ M_{12} ~ ~ \cdots ~ ~ M_ {1N}\\\\ M_{21} ~ ~ M_{22} ~ ~ \cdots ~ ~ M_ {2N}\\\\ \ddots\\\\ M_ {M1} ~ ~ M_ {m2} ~ ~ \cdots ~ ~ M_ {MN} \end{bmatrix} \begin{bmatrix} N_{11} ~ ~ N_{12} ~ ~ \cdots ~ ~ N_ {1P}\\\\ N_{21} ~ ~ N_{22} ~ ~ \cdots ~ ~ N_ {2P}\\\\ \ddots\\\\ N_ {N1} ~ ~ N_ {N2} ~ ~ \cdots ~ ~ N_ {NP} \end{bmatrix} = \begin{bmatrix} P_{11} ~ ~ P_{12} ~ ~ \cdots ~ ~ P_ {1P}\\\\ P_{21} ~ ~ P_{22} ~ ~ \cdots ~ ~ P_ {2P}\\\\ \ddots\\\\ P_ {M1} ~ ~ P_ {m2} ~ ~ \cdots ~ ~ P_ {MP} \end{bmatrix} \end{align}</span><span class="sxs-lookup"><span data-stu-id="23687-127">\begin{align} &\begin{bmatrix} M_{11} ~~ M_{12} ~~ \cdots ~~ M_{1n}\\\\ M_{21} ~~ M_{22} ~~ \cdots ~~ M_{2n}\\\\ \ddots\\\\ M_{m1} ~~ M_{m2} ~~ \cdots ~~ M_{mn} \end{bmatrix} \begin{bmatrix} N_{11} ~~ N_{12} ~~ \cdots ~~ N_{1p}\\\\ N_{21} ~~ N_{22} ~~ \cdots ~~ N_{2p}\\\\ \ddots\\\\ N_{n1} ~~ N_{n2} ~~ \cdots ~~ N_{np} \end{bmatrix}=\begin{bmatrix} P_{11} ~~ P_{12} ~~ \cdots ~~ P_{1p}\\\\ P_{21} ~~ P_{22} ~~ \cdots ~~ P_{2p}\\\\ \ddots\\\\ P_{m1} ~~ P_{m2} ~~ \cdots ~~ P_{mp} \end{bmatrix} \end{align}</span></span>

<span data-ttu-id="23687-128">Wenn die Einträge von $P $ $P _ {IK} = \ sum_j M_ {IJ} N_ {JK} $ sind.</span><span class="sxs-lookup"><span data-stu-id="23687-128">where the entries of $P$ are $P_{ik} = \sum_j M_{ij}N_{jk}$.</span></span> <span data-ttu-id="23687-129">Beispielsweise ist der Eintrag $P _{11}$ das innere Produkt der ersten Zeile von $M $ mit der ersten Spalte $N $.</span><span class="sxs-lookup"><span data-stu-id="23687-129">For example, the entry $P_{11}$ is the inner product of the first row of $M$ with the first column of $N$.</span></span> <span data-ttu-id="23687-130">Beachten Sie, dass sich diese Definition auf die Matrix Vektor Multiplikation erstreckt, da ein Vektor einfach ein Sonderfall einer Matrix ist.</span><span class="sxs-lookup"><span data-stu-id="23687-130">Note that since a vector is simply a special case of a matrix, this definition extends to matrix-vector multiplication.</span></span> 

<span data-ttu-id="23687-131">Alle Matrizen, die wir in Erwägung gezogen, sind entweder quadratische Matrizen, bei denen die Anzahl der Zeilen und Spalten gleich ist, oder Vektoren, die nur $1 $-Spalten entsprechen.</span><span class="sxs-lookup"><span data-stu-id="23687-131">All the matrices we consider will either be square matrices, where the number of rows and columns are equal, or vectors, which corresponds to only $1$ column.</span></span> <span data-ttu-id="23687-132">Eine spezielle quadratische Matrix ist die [*Identitätsmatrix*](https://en.wikipedia.org/wiki/Identity_matrix), die "$ \boldone $" bezeichnet und deren diagonale Elemente gleich $1 $ und die restlichen Elemente gleich $0 $ sind:</span><span class="sxs-lookup"><span data-stu-id="23687-132">One special square matrix is the [*identity matrix*](https://en.wikipedia.org/wiki/Identity_matrix), denoted $\boldone$, which has all its diagonal elements equal to $1$ and the remaining elements equal to $0$:</span></span>

<span data-ttu-id="23687-133">$ $ \boldone = \begin{bmatrix} 1 ~ ~ 0 ~ ~ \cdots ~ ~ 0\\\\ 0 ~ ~ 1 ~ ~ \cdots ~ ~ 0\\\\ ~ ~ \ddots\\\\ 0 ~ ~ 0 ~ ~ \cdots ~ ~ 1 \end{bmatrix}. $ $</span><span class="sxs-lookup"><span data-stu-id="23687-133">$$\boldone=\begin{bmatrix} 1 ~~ 0 ~~ \cdots ~~ 0\\\\ 0 ~~ 1 ~~ \cdots ~~ 0\\\\ ~~ \ddots\\\\ 0 ~~ 0 ~~ \cdots ~~ 1 \end{bmatrix}.$$</span></span>

<span data-ttu-id="23687-134">Für eine quadratische Matrix $A $ sagen wir, dass eine Matrix $B $ die [*umgekehrte*](https://en.wikipedia.org/wiki/Invertible_matrix) ist, wenn $ab = BA = \boldone $ ist.</span><span class="sxs-lookup"><span data-stu-id="23687-134">For a square matrix $A$, we say a matrix $B$ is its [*inverse*](https://en.wikipedia.org/wiki/Invertible_matrix) if $AB = BA = \boldone$.</span></span> <span data-ttu-id="23687-135">Die Umkehrung einer Matrix muss nicht vorhanden sein. Wenn Sie jedoch vorhanden ist, ist sie eindeutig, und wir bezeichnen Sie $A ^{-1}$.</span><span class="sxs-lookup"><span data-stu-id="23687-135">The inverse of a matrix need not exist, but when it exists it is unique and we denote it $A^{-1}$.</span></span> 

<span data-ttu-id="23687-136">Bei allen Matrizen $M $ ist das Adjoint oder konjugierte $M $ eine Matrix $N $, sodass $N _ {IJ} = M_ {JI} ^\*$ ist.</span><span class="sxs-lookup"><span data-stu-id="23687-136">For any matrix $M$, the adjoint or conjugate transpose of $M$ is a matrix $N$ such that $N_{ij} = M_{ji}^\*$.</span></span> <span data-ttu-id="23687-137">Das Adjoint-$M $ wird normalerweise $M ^ \dagger $ bezeichnet.</span><span class="sxs-lookup"><span data-stu-id="23687-137">The adjoint of $M$ is usually denoted $M^\dagger$.</span></span> <span data-ttu-id="23687-138">Wir sagen, dass eine Matrix $U $ [*einheitlich*](https://en.wikipedia.org/wiki/Unitary_matrix) ist, wenn $UU ^ \dagger = u ^ \dagger U = \boldone $ oder gleichwertig $U ^{-1} = u ^ \dagger $.</span><span class="sxs-lookup"><span data-stu-id="23687-138">We say a matrix $U$ is [*unitary*](https://en.wikipedia.org/wiki/Unitary_matrix) if $UU^\dagger = U^\dagger U = \boldone$ or equivalently, $U^{-1} = U^\dagger$.</span></span>  <span data-ttu-id="23687-139">Die wichtigste Eigenschaft der einheitlichen Matrizen ist, dass Sie die Norm eines Vektors erhalten.</span><span class="sxs-lookup"><span data-stu-id="23687-139">Perhaps the most important property of unitary matrices is that they preserve the norm of a vector.</span></span>  <span data-ttu-id="23687-140">Dies liegt daran, dass</span><span class="sxs-lookup"><span data-stu-id="23687-140">This happens because</span></span> 

<span data-ttu-id="23687-141">$ $ \langle v, v \rangle = v ^ \dagger v = v ^ \dagger u ^{-1} U v = v ^ \dagger u ^ \dagger u v = \langle u v, u v\rangle. $ $</span><span class="sxs-lookup"><span data-stu-id="23687-141">$$\langle v,v \rangle=v^\dagger v = v^\dagger U^{-1} U v = v^\dagger U^\dagger U v = \langle U v, U v\rangle.$$</span></span>  

<span data-ttu-id="23687-142">Eine Matrix $M $ heißt [*hermitian*](https://en.wikipedia.org/wiki/Hermitian_matrix) , wenn $M = M ^ \dagger $.</span><span class="sxs-lookup"><span data-stu-id="23687-142">A matrix $M$ is said to be [*Hermitian*](https://en.wikipedia.org/wiki/Hermitian_matrix) if $M=M^\dagger$.</span></span>

<span data-ttu-id="23687-143">Schließlich ist das [*tensorflow-Produkt*](https://en.wikipedia.org/wiki/Tensor_product) (oder Kronecker-Produkt) von zwei Matrizen $M $ der Größe $m \times n $ und $N $ der Größe $p \times q $ eine größere Matrix $P = m\otimes n $ der Größe $MP \times NQ $ und wird wie folgt aus $M $ und $N $ abgerufen:</span><span class="sxs-lookup"><span data-stu-id="23687-143">Finally, the [*tensor product*](https://en.wikipedia.org/wiki/Tensor_product) (or Kronecker product) of two matrices $M$ of size $m\times n$ and $N$ of size $p \times q$ is a larger matrix $P=M\otimes N$ of size $mp \times nq$, and is obtained from $M$ and $N$ as follows:</span></span>

<span data-ttu-id="23687-144">\begin{align} M \otimes N & = \begin{bmatrix} M_{11} ~ ~ \cdots ~ ~ M_ {1N} \\\\ \ddots\\\\ M_ {M1} ~ ~ \cdots ~ ~ M_ {MN} \end{bmatrix} \otimes \begin{bmatrix} N_{11} ~ ~ \cdots ~ ~ N_ {1Q}\\\\ \dpunkte\\\\ N_ {P1} ~ ~ \cdots ~ ~ N_ {PQ} \end{bmatrix}\\\\ & = \begin{bmatrix} M_{11} \begin{bmatrix} N_{11} ~ ~ \cdots ~ ~ N_ {1Q}\\\\ \ddots\\\\ N_ {P1} ~ ~ \cdots ~ ~ N_ {PQ} \end{bmatrix} ~ ~ \cdots ~ ~ M_ {1N} \begin{bmatrix} N_{11} ~ ~ \cdots ~ ~ N_ {1Q}\\\\ \ddots\\\\ N_ {P1} ~ ~ \ cdots ~ ~ N_ {PQ} \end{bmatrix}\\\\ \ddots\\\\ M_ {M1} \begin{bmatrix} N_{11} ~ ~ \cdots ~ ~ N_ {1Q}\\\\ \ddots\\\\ N_ {P1} ~ ~ \cdots ~ ~ N_ {PQ} \end{bmatrix} ~ ~ \cdots ~ ~ M_ {MN} \begin{bmatrix} N_{11} ~ ~ \cdots ~ ~ N_ {1Q}\\\\ \ddots\\\\ N_ {P1} ~ ~ \cdots ~ ~ N_ {PQ} \end{ bmatrix} \end{bmatrix}.</span><span class="sxs-lookup"><span data-stu-id="23687-144">\begin{align} M \otimes N &= \begin{bmatrix} M_{11} ~~ \cdots ~~ M_{1n} \\\\ \ddots\\\\ M_{m1}  ~~ \cdots ~~ M_{mn} \end{bmatrix} \otimes \begin{bmatrix} N_{11}  ~~ \cdots ~~ N_{1q}\\\\ \ddots\\\\ N_{p1} ~~ \cdots ~~ N_{pq} \end{bmatrix}\\\\ &= \begin{bmatrix} M_{11} \begin{bmatrix} N_{11}  ~~ \cdots ~~ N_{1q}\\\\ \ddots\\\\ N_{p1} ~~ \cdots ~~ N_{pq} \end{bmatrix}~~ \cdots ~~ M_{1n} \begin{bmatrix} N_{11}  ~~ \cdots ~~ N_{1q}\\\\ \ddots\\\\ N_{p1} ~~ \cdots ~~ N_{pq} \end{bmatrix}\\\\ \ddots\\\\ M_{m1} \begin{bmatrix} N_{11}  ~~ \cdots ~~ N_{1q}\\\\ \ddots\\\\ N_{p1} ~~ \cdots ~~ N_{pq} \end{bmatrix}~~ \cdots ~~ M_{mn} \begin{bmatrix} N_{11}  ~~ \cdots ~~ N_{1q}\\\\ \ddots\\\\ N_{p1} ~~ \cdots ~~ N_{pq} \end{bmatrix} \end{bmatrix}.</span></span>
<span data-ttu-id="23687-145">\end{align}</span><span class="sxs-lookup"><span data-stu-id="23687-145">\end{align}</span></span>

<span data-ttu-id="23687-146">Dies wird in einigen Beispielen besser veranschaulicht:</span><span class="sxs-lookup"><span data-stu-id="23687-146">This is better demonstrated with some examples:</span></span>

<span data-ttu-id="23687-147">$ $ \begin{bmatrix} a \\\\ b \end{bmatrix} \otimes \begin{bmatrix} c \\\\ d \\\\ e \end{bmatrix} = \begin{bmatrix} a \begin{bmatrix} c \\\\ d \\\\ e \end{bmatrix} \\\\[1.5 em] b \begin{bmatrix} c \\\\ d \\\\ e\end {bmatrix} \end{bmatrix} = \begin{bmatrix} a c \\\\ a d \\\\ a e \\\\ b c \\\\ b d \\\\ be\ende {bmatrix} $ $</span><span class="sxs-lookup"><span data-stu-id="23687-147">$$ \begin{bmatrix} a \\\\ b  \end{bmatrix} \otimes \begin{bmatrix} c \\\\ d \\\\ e \end{bmatrix} = \begin{bmatrix} a \begin{bmatrix} c \\\\ d \\\\ e \end{bmatrix} \\\\[1.5em] b \begin{bmatrix} c \\\\ d \\\\ e\end{bmatrix} \end{bmatrix} = \begin{bmatrix} a c \\\\ a d \\\\ a e \\\\ b c \\\\ b d \\\\ be\end{bmatrix} $$</span></span>

<span data-ttu-id="23687-148">and</span><span class="sxs-lookup"><span data-stu-id="23687-148">and</span></span>

<span data-ttu-id="23687-149">$ $ \begin{bmatrix} a \ b \\\\ c \ d \end{bmatrix} \otimes \begin{bmatrix} e \ f\\\\g \ h \end{bmatrix} = \begin{bmatrix} a\begin {bmatrix} e \ f\\\\ g \ h \end{bmatrix} b\begin {bmatrix} e \ f\\\\ g \ h \end{bmatrix} \\\\[1em] c\begin {bmatrix} e \ f\\\\ g \ h \end{bmatrix} d\begin {bmatrix} e \ f\\\\ g \ h \end{bmatrix} \end{bmatrix} = \begin{bmatrix} AE \ AF \ be \ BF \\@no__ t_15_ AG \ AH \ BG \ BH \\\\ CE \ CF \ de \ DF \\\\ CG \ ch \ DG \ dh \end{bmatrix}.\\</span><span class="sxs-lookup"><span data-stu-id="23687-149">$$ \begin{bmatrix} a\ b \\\\ c\ d \end{bmatrix} \otimes \begin{bmatrix} e\ f\\\\g\ h \end{bmatrix} = \begin{bmatrix} a\begin{bmatrix} e\ f\\\\ g\ h \end{bmatrix} b\begin{bmatrix} e\ f\\\\ g\ h \end{bmatrix} \\\\[1em] c\begin{bmatrix} e\ f\\\\ g\ h \end{bmatrix} d\begin{bmatrix} e\ f\\\\ g\ h \end{bmatrix} \end{bmatrix} = \begin{bmatrix} ae\ af\ be\ bf \\\\ ag\ ah\ bg\ bh \\\\ ce\ cf\ de\ df \\\\ cg\ ch\ dg\ dh \end{bmatrix}.</span></span>
$$

<span data-ttu-id="23687-150">Eine abschließende, nützliche, in Bezug auf die tensorflow-Produkte für alle Vektor $v $ oder Matrix $M $, $v ^ {\otimes n} $ oder $M ^ {\otimes n} $ ist eine kurze Hand für ein $n $-Fold-tensorflow-Produkt.</span><span class="sxs-lookup"><span data-stu-id="23687-150">A final useful notational convention surrounding tensor products is that, for any vector $v$ or matrix $M$, $v^{\otimes n}$ or $M^{\otimes n}$ is short hand for an $n$-fold repeated tensor product.</span></span>  <span data-ttu-id="23687-151">Beispiel:</span><span class="sxs-lookup"><span data-stu-id="23687-151">For example:</span></span>

<span data-ttu-id="23687-152">\begin{align} & \begin{bmatrix} 1 \\\\ 0 \ End{bmatrix} ^ {\otimes 1} = \begin{bmatrix} 1 \\\\ 0 \end{bmatrix}, \qquad\begin{bmatrix} 1 \\\\ 0 \ End{bmatrix} ^ {\otimes 2} = \begin{bmatrix} 1 \\\\ 0 \\\\0 \\\\0 \end{bmatrix}, \qquad\begin{bmatrix} 1 \\\\-1 \ End{bmatrix} ^ {\otimes 2} = \begin{bmatrix} 1 \\\\-1 \\\\-1 \\\\1 \ End{ bmatrix}, \\\\ & \begin{bmatrix} 0 & 1 \\\\ 1 & 0 \ End{bmatrix} ^ {\otimes 1} = \begin{bmatrix} 0 & 1 \\\\ 1 & 0 \end{bmatrix}, \qquad\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \end{bmatrix} ^ {\otimes 2} = \begin{bmatrix} 0 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 0\\\\ 1 & 0 & 0 & 0 \ Ende { bmatrix}.</span><span class="sxs-lookup"><span data-stu-id="23687-152">\begin{align} &\begin{bmatrix} 1 \\\\ 0 \end{bmatrix}^{\otimes 1} = \begin{bmatrix} 1 \\\\ 0 \end{bmatrix}, \qquad\begin{bmatrix} 1 \\\\ 0 \end{bmatrix}^{\otimes 2} = \begin{bmatrix} 1 \\\\ 0 \\\\0 \\\\0 \end{bmatrix}, \qquad\begin{bmatrix} 1 \\\\ -1 \end{bmatrix}^{\otimes 2} = \begin{bmatrix} 1 \\\\ -1 \\\\-1 \\\\1 \end{bmatrix}, \\\\ &\begin{bmatrix}  0 & 1 \\\\ 1& 0     \end{bmatrix}^{\otimes 1}= \begin{bmatrix}  0& 1 \\\\ 1& 0  \end{bmatrix},  \qquad\begin{bmatrix}   0 & 1 \\\\ 1& 0     \end{bmatrix}^{\otimes 2}= \begin{bmatrix} 0 &0&0&1 \\\\ 0 &0&1&0 \\\\ 0 &1&0&0\\\\ 1 &0&0&0\end{bmatrix}.</span></span>
<span data-ttu-id="23687-153">\end{align}</span><span class="sxs-lookup"><span data-stu-id="23687-153">\end{align}</span></span>
